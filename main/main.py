"""
EMA (Engineering Mathematics Assistant) ë©”ì¸ ì‹¤í–‰ íŒŒì¼
"""
import os
import uuid
import warnings
import re, json
import base64
from fastapi import FastAPI, HTTPException, status
from pydantic import BaseModel, Field
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.runnables import RunnableConfig
from workflow import graph
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings

warnings.filterwarnings("ignore", message="Convert_system_message_to_human will be deprecated!")
config = RunnableConfig(recursion_limit=10, configurable={"thread_id": str(uuid.uuid4())})

def process_query(query: str) -> str:
    """
    ì‚¬ìš©ì ì§ˆì˜ë¥¼ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        query (str): ì‚¬ìš©ìì˜ ì§ˆì˜

    Returns:
        str: ì‹œìŠ¤í…œì˜ ì‘ë‹µ
    """
    print(f"ì‚¬ìš©ì ì§ˆì˜ ì²˜ë¦¬ ì‹œì‘: {query}")

    state = {"messages": [HumanMessage(content=query, name="User")]}

    try:
        for step in graph.stream(state, config=config):
            if step:
                node_name = list(step.keys())[0]
                print(f"ğŸ”„ ì‹¤í–‰ ì¤‘: {node_name}")

        final_state = graph.get_state(config=config)
        messages = final_state.values['messages']

        ai_messages = [msg for msg in messages if isinstance(msg, AIMessage)]
        if ai_messages:
            final_message = ai_messages[-1].content
        else:
            final_message = messages[-1].content if messages else "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        return final_message

    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash",
    google_api_key=GOOGLE_API_KEY,
    convert_system_message_to_human=True,
    temperature=0.2
)
app = FastAPI(
    title="Calc-Question Generator API",
    description="ë¯¸ì ë¶„ ê°ê´€ì‹ ë¬¸ì œë¥¼ ìƒì„±í•˜ëŠ” REST API",
    version="1.0.0",
)

# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
# ë¬¸ì œìƒì„± api
# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
class QuestionRequest(BaseModel):
    topics: str           = Field(..., example="í•¨ìˆ˜ì˜ ê·¹í•œ í™•ì¸ë¬¸ì œ")
    range_: str           = Field(..., alias="range", example="2.2 The Limit of Functions")
    summarized: str       = Field(..., example="ê·¹í•œì˜ ì •ì˜, í•œìª½Â·ë¬´í•œ ê·¹í•œ, ìˆ˜ì§ ì ê·¼ì„ ")
    difficulty: str       = Field(..., example="í’€ì´ 5ì¤„ ì´ë‚´")
    quiz_examples: str    = Field(..., example="(ì˜ˆì‹œ ë¬¸ì œ)")

class QuestionResponse(BaseModel):
    question: str
    choice1: str
    choice2: str
    choice3: str
    choice4: str
    choice5: str
    answer: int
    solution: str

@app.post(
    "/questions",
    response_model=QuestionResponse,
    summary="ê°ê´€ì‹ ë¬¸ì œ ìƒì„±",
    status_code=status.HTTP_201_CREATED,
)
async def create_question(payload: QuestionRequest):
    """
    LangChain + OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•´ ê°ê´€ì‹ ë¬¸ì œë¥¼ ìƒì„±í•˜ì—¬ JSON ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        # 1) payload â†’ JSON string
        payload_str = payload.model_dump_json(by_alias=True)
        # 2) 1ì°¨ LLM ìš”ì²­: â€œë¬¸ì œ ìƒì„±â€
        query = (
            "ë‹¤ìŒ JSONì„ ê¸°ë°˜ìœ¼ë¡œ, ê°ê´€ì‹ ë¬¸ì œë¥¼ â€˜ì‚¬ëŒì´ ì½ê¸° í¸í•œâ€™ í˜•ì‹ìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜.\n"
            f"{payload_str}"
        )
        raw_result: str = process_query(query)
        # 3) 2ì°¨ LLM ìš”ì²­: â€œJSONìœ¼ë¡œ ë³€í™˜â€
        json_prompt = (
            "ìœ„ì—ì„œ ìƒì„±ëœ ë¬¸ì œë¥¼, ì•„ë˜ ìŠ¤í‚¤ë§ˆì— ë§ì¶° **ìˆœìˆ˜ JSON**ìœ¼ë¡œë§Œ ë³€í™˜í•´ì¤˜.\n"
            "í‚¤: question, choice1~choice5, answer(ì •ë‹µ ë²ˆí˜¸, 1~5), solution\n\n"
            f"{raw_result}"
        )
        response = await llm.agenerate([[HumanMessage(content=json_prompt)]])
        json_str = response.generations[0][0].text.strip()
        # 3-4) JSON â†’ Pydantic ëª¨ë¸
        match = re.search(r"```(?:json)?\s*(\{.*\})\s*```", json_str, re.S)
        clean_json = match.group(1) if match else json_str
        data = json.loads(clean_json)
        return QuestionResponse(**data)

    except Exception as e:
        # í•„ìš” ì‹œ ì„¸ë¶„í™”ëœ ì˜ˆì™¸ ì²˜ë¦¬
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e),
        )

# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
# ì§ˆì˜ì‘ë‹µ api
# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
class QARequest(BaseModel):
    query: str = Field(..., example="í•¨ìˆ˜ì˜ ê·¹í•œì´ë€ ë¬´ì—‡ì¸ê°€ìš”?")

class QAResponse(BaseModel):
    answer: str

@app.post(
    "/qna",
    response_model=QAResponse,
    summary="ì‚¬ìš©ì ì§ˆì˜ì‘ë‹µ",
    status_code=status.HTTP_200_OK,
)
async def answer_query(payload: QARequest):
    """
    ì‚¬ìš©ìë¡œë¶€í„° ë°›ì€ ì§ˆì˜ë¥¼ AI ê·¸ë˜í”„ì— ì „ë‹¬í•´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        result = process_query(payload.query)
        return QAResponse(answer=result)
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e),
        )

# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
# ì§ˆì˜ì‘ë‹µ + ì œëª© api
# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
class QATResponse(BaseModel):
    answer: str
    title: str

@app.post(
    "/qnantitle",
    response_model=QATResponse,
    summary="ì‚¬ìš©ì ì§ˆì˜ì‘ë‹µ",
    status_code=status.HTTP_200_OK,
)
async def answer_query(payload: QARequest):
    """
    ì‚¬ìš©ìë¡œë¶€í„° ë°›ì€ ì§ˆì˜ë¥¼ AI ê·¸ë˜í”„ì— ì „ë‹¬í•´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        result = process_query(payload.query)
        prompt = f"""System:
        ë‹¹ì‹ ì€ â€˜ì±„íŒ…ë°© ì œëª© ìƒì„±ê¸°(Chat Title Generator)â€™ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìê°€ ë³´ë‚¸ ë©”ì‹œì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„, ê·¸ ë©”ì‹œì§€ì˜ í•µì‹¬ ì£¼ì œë¥¼ 3~6ê°œì˜ ë‹¨ì–´ë¡œ ìš”ì•½í•œ ì§§ê³  ëª…í™•í•œ ì œëª©ì„ ì¶œë ¥í•˜ì„¸ìš”.
        â€¢ ì œëª©ì—ëŠ” ë¶ˆí•„ìš”í•œ ì¡°ì‚¬ë‚˜ ì ‘ì†ì‚¬ë¥¼ ì“°ì§€ ë§ˆì„¸ìš”.
        â€¢ êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë¥¼ í¬í•¨í•´ ëŒ€í™” ë‚´ìš©ì„ í•œëˆˆì— ì•Œ ìˆ˜ ìˆê²Œ ì‘ì„±í•˜ì„¸ìš”.
        â€¢ ì¶œë ¥ í˜•ì‹ì€ **ì œëª©** í…ìŠ¤íŠ¸ë§Œ, ë”°ì˜´í‘œë‚˜ ì¶”ê°€ ì„¤ëª… ì—†ì´ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

        User:
        {payload.query}"""


        response = await llm.agenerate([[HumanMessage(content=prompt)]])
        tit = response.generations[0][0].text.strip()
        print("***** tit = ", tit)

        return QATResponse(answer=result, title=tit)
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e),
        )


# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
# ì§ˆì˜ì‘ë‹µ ì´ë¯¸ì§€ + ë¬¸ì api
# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
class QAImageRequest(BaseModel):
    query: str = Field(..., example="í•¨ìˆ˜ì˜ ê·¹í•œì´ë€ ë¬´ì—‡ì¸ê°€ìš”?")
    image_base64: str = Field(
        ...,
        description="data:image/png;base64, ë¡œ ì‹œì‘í•˜ëŠ” Base64 ì¸ì½”ë”© ì´ë¯¸ì§€ ë¬¸ìì—´",
        example="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA..."
    )

@app.post(
    "/qnaimg",
    response_model=QAResponse,
    summary="ì‚¬ìš©ì ì§ˆì˜ì‘ë‹µ",
    status_code=status.HTTP_200_OK,
)
async def answer_query(payload: QAImageRequest):
    try:


        # 3) ì§ˆì˜ + ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ê·¸ë˜í”„ ìƒíƒœì— ì‚½ì…
        state = {
            "messages": [
                HumanMessage(
                    content=[
                        {
                            "type": "text",
                            "text": ""
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": payload.image_base64
                            }
                        }
                    ],
                    name="User"
                )
            ]
        }

        for step in graph.stream(state, config=config):
            if step:
                node_name = list(step.keys())[0]
                print(f"ğŸ”„ ì‹¤í–‰ ì¤‘: {node_name}")

        final_state = graph.get_state(config=config)
        messages = final_state.values['messages']

        ai_messages = [msg for msg in messages if isinstance(msg, AIMessage)]
        if ai_messages:
            final_message = ai_messages[-1].content
        else:
            final_message = messages[-1].content if messages else "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        return QAResponse(answer=final_message)
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e),
        )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True, log_level="debug")
