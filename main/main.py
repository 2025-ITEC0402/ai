"""
EMA (Engineering Mathematics Assistant) ë©”ì¸ ì‹¤í–‰ íŒŒì¼
"""
import os
import uuid
import warnings
import re, json
import base64
from fastapi import FastAPI, HTTPException, status
from pydantic import BaseModel, Field
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.runnables import RunnableConfig
from workflow import graph
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
import traceback 
warnings.filterwarnings("ignore", message="Convert_system_message_to_human will be deprecated!")

def process_query(query: str) -> str:
    """
    ì‚¬ìš©ì ì§ˆì˜ë¥¼ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        query (str): ì‚¬ìš©ìì˜ ì§ˆì˜

    Returns:
        str: ì‹œìŠ¤í…œì˜ ì‘ë‹µ
    """
    print(f"ì‚¬ìš©ì ì§ˆì˜ ì²˜ë¦¬ ì‹œì‘: {query}")

    state = {"messages": [HumanMessage(content=query, name="User")]}
    config = RunnableConfig(recursion_limit=10)
    try:
        final_state = graph.invoke(state, config=config)
        messages = final_state['messages']
        final_message = messages[-1].content if messages else "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        return final_message

    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"ì˜¤ë¥˜ íƒ€ì…: {type(e)}")
        print(f"ì˜¤ë¥˜ ìƒì„¸ ì •ë³´ (Traceback): \n{traceback.format_exc()}")
        return

load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash",
    google_api_key=GOOGLE_API_KEY,
    convert_system_message_to_human=True,
    temperature=0.2
)
app = FastAPI(
    title="Calc-Question Generator API",
    description="ë¯¸ì ë¶„ ê°ê´€ì‹ ë¬¸ì œë¥¼ ìƒì„±í•˜ëŠ” REST API",
    version="1.0.0",
)

# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
# ë¬¸ì œìƒì„± api
# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
class QuestionRequest(BaseModel):
    topics: str           = Field(..., example="í•¨ìˆ˜ì˜ ê·¹í•œ í™•ì¸ë¬¸ì œ")
    range_: str           = Field(..., alias="range", example="2.2 The Limit of Functions")
    summarized: str       = Field(..., example="ê·¹í•œì˜ ì •ì˜, í•œìª½Â·ë¬´í•œ ê·¹í•œ, ìˆ˜ì§ ì ê·¼ì„ ")
    difficulty: str       = Field(..., example="í’€ì´ 5ì¤„ ì´ë‚´")
    quiz_examples: str    = Field(..., example="(ì˜ˆì‹œ ë¬¸ì œ)")

class QuestionResponse(BaseModel):
    question: str
    choice1: str
    choice2: str
    choice3: str
    choice4: str
    choice5: str
    answer: int
    solution: str

@app.post(
    "/questions",
    response_model=QuestionResponse,
    summary="ê°ê´€ì‹ ë¬¸ì œ ìƒì„±",
    status_code=status.HTTP_201_CREATED,
)
async def create_question(payload: QuestionRequest):
    """
    LangChain + OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•´ ê°ê´€ì‹ ë¬¸ì œë¥¼ ìƒì„±í•˜ì—¬ JSON ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        # 1) payload â†’ JSON string
        payload_str = payload.model_dump_json(by_alias=True)
        # 2) 1ì°¨ LLM ìš”ì²­: â€œë¬¸ì œ ìƒì„±â€
        query = (
            "ë‹¤ìŒ JSONì„ ê¸°ë°˜ìœ¼ë¡œ, ê°ê´€ì‹ ë¬¸ì œë¥¼ â€˜ì‚¬ëŒì´ ì½ê¸° í¸í•œâ€™ í˜•ì‹ìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜.\n"
            f"{payload_str}"
        )
        raw_result: str = process_query(query)
        # 3) 2ì°¨ LLM ìš”ì²­: â€œJSONìœ¼ë¡œ ë³€í™˜â€
        json_prompt = (
            "ìœ„ì—ì„œ ìƒì„±ëœ ë¬¸ì œë¥¼, ì•„ë˜ ìŠ¤í‚¤ë§ˆì— ë§ì¶° **ìˆœìˆ˜ JSON**ìœ¼ë¡œë§Œ ë³€í™˜í•´ì¤˜.\n"
            "í‚¤: question, choice1~choice5, answer(ì •ë‹µ ë²ˆí˜¸, 1~5), solution\n\n"
            f"{raw_result}"
        )
        response = await llm.agenerate([[HumanMessage(content=json_prompt)]])
        json_str = response.generations[0][0].text.strip()
        # 3-4) JSON â†’ Pydantic ëª¨ë¸
        match = re.search(r"```(?:json)?\s*(\{.*\})\s*```", json_str, re.S)
        clean_json = match.group(1) if match else json_str
        data = json.loads(clean_json)
        return QuestionResponse(**data)

    except Exception as e:
        # í•„ìš” ì‹œ ì„¸ë¶„í™”ëœ ì˜ˆì™¸ ì²˜ë¦¬
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e),
        )

# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
# new ë¬¸ì œìƒì„± api
# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
class NewQuestionRequest(BaseModel):
    topics: str           = Field(..., example="í•¨ìˆ˜ì˜ ê·¹í•œ í™•ì¸ë¬¸ì œ")
    range_: str           = Field(..., alias="range", example="2.2 The Limit of Functions")
    summarized: str       = Field(..., example="ê·¹í•œì˜ ì •ì˜, í•œìª½Â·ë¬´í•œ ê·¹í•œ, ìˆ˜ì§ ì ê·¼ì„ ")
    difficulty: str       = Field(..., example="3")
    quiz_examples: str    = Field(..., example="(ì˜ˆì‹œ ë¬¸ì œ)")

class NewQuestionResponse(BaseModel):
    chapter : str
    question: str
    choice1: str
    choice2: str
    choice3: str
    choice4: str
    answer: int
    solution: str
    difficulty: str
    ai_summary: str

@app.post(
    "/newquestions",
    response_model=NewQuestionResponse,
    summary="ê°ê´€ì‹ ë¬¸ì œ ìƒì„±",
    status_code=status.HTTP_201_CREATED,
)
async def create_question(payload: NewQuestionRequest):
    """
    LangChain + OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•´ ê°ê´€ì‹ ë¬¸ì œë¥¼ ìƒì„±í•˜ì—¬ JSON ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        # 1) payload â†’ JSON string
        payload_str = payload.model_dump_json(by_alias=True)
        # 2) 1ì°¨ LLM ìš”ì²­: â€œë¬¸ì œ ìƒì„±â€
        query = (
            "ë‹¤ìŒ JSONì„ ê¸°ë°˜ìœ¼ë¡œ ê°ê´€ì‹ ë¬¸ì œë¥¼ ë§Œë“¤ì–´ì¤˜. ê·¸ë¦¬ê³  ê·¸ ë¬¸ì œë¥¼ í’€ì–´ì¤˜.\n"
            f"{payload_str}"
        )
        raw_result: str = process_query(query)
        print("***** raw_result = ", raw_result)
        # 3) 2ì°¨ LLM ìš”ì²­: â€œJSONìœ¼ë¡œ ë³€í™˜â€
        json_prompt = f"""
        ë‹¹ì‹ ì€ êµìœ¡ìš© ë¬¸ì œ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ í¬ë§·íŒ…í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ ì…ë ¥(input) ë¬¸ìì—´ì— í¬í•¨ëœ ëª¨ë“  ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬, ë°˜ë“œì‹œ ë‹¤ìŒ ìŠ¤í‚¤ë§ˆì— ë§ëŠ” JSONì„ ìƒì„±í•˜ì„¸ìš”.
        
        --- ìŠ¤í‚¤ë§ˆ ì„¤ëª… (NewQuestionResponse) ---
        - chapter    : ë¬¸ìì—´ (ì˜ˆ: "í•¨ìˆ˜ì™€ ëª¨ë¸ (Functions and Models)", "ì ë¶„ë¡ " ë“±)
        - question   : ë¬¸ìì—´ (ë¬¸ì œ ì§€ë¬¸)
        - choice1    : ë¬¸ìì—´ (ì„ íƒì§€ 1)
        - choice2    : ë¬¸ìì—´ (ì„ íƒì§€ 2)
        - choice3    : ë¬¸ìì—´ (ì„ íƒì§€ 3)
        - choice4    : ë¬¸ìì—´ (ì„ íƒì§€ 4)
        - answer     : ì •ìˆ˜ (1~4 ì¤‘ í•˜ë‚˜; ì •ë‹µì´ ëª‡ ë²ˆ ì„ íƒì§€ì¸ì§€)
        - solution   : ë¬¸ìì—´ (ë¬¸ì œ í’€ì´ ê³¼ì •ì´ë‚˜ í•´ì„¤)
        - difficulty : ë¬¸ìì—´(Easy,Normal,Hard ì¤‘ í•˜ë‚˜)
        - ai_summary : ë¬¸ìì—´(ë¬¸ì œ í•œì¤„í‰)

        â€» ì£¼ì˜ì‚¬í•­
        1. **answer** í•„ë“œëŠ” ë°˜ë“œì‹œ 1, 2, 3, 4 ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.
        2. **difficulty** í•„ë“œëŠ” ë°˜ë“œì‹œ 1, 2, 3 ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.
        3. ì¶œë ¥ì€ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì´ë£¨ì–´ì ¸ì•¼ í•˜ê³ , ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ì£¼ì„ì„ í¬í•¨í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.
        4. í•˜ë‚˜ì˜ JSON ê°ì²´ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        
        --- input ë¬¸ìì—´ ---
        {raw_result}
        
        --- JSON ì˜ˆì‹œ ---
        ```json
        {{
          "chapter": "í•¨ìˆ˜ì™€ ëª¨ë¸ (Functions and Models)",
          "question": "í•¨ìˆ˜ f(x)=x^2+2x+1ì˜ ê·¹ê°’ì„ êµ¬í•˜ì‹œì˜¤.",
          "choice1": "x=-1",
          "choice2": "x=0",
          "choice3": "x=1",
          "choice4": "x=2",
          "answer": 1,
          "solution": "ë„í•¨ìˆ˜ f'(x)=2x+2. f'(x)=0 â‡’ x=-1ì´ ê·¹ê°’ì´ê³ , f''(x)=2>0ì´ë¯€ë¡œ ìµœì†Ÿê°’ì´ë‹¤.",
          "difficulty": "Normal"
          "ai_summary": "ê¸°ë³¸ì ì¸ ë„í•¨ìˆ˜ ê³„ì‚°ê³¼ ê·¹ê°’ íŒë³„ì„ ë¬»ëŠ” ë¬¸ì œì…ë‹ˆë‹¤."
          ""
        }}
        ```
        ìœ„ ì˜ˆì‹œì—ì„œëŠ”
        
        "answer": 1 (ì„ íƒì§€ 1ì´ ì •ë‹µ)
        
        "difficulty": "Normal" (ë³´í†µ ë‚œì´ë„)
        
        ìœ„ input ë¬¸ìì—´ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë™ì¼í•œ í˜•ì‹ì˜ JSON ê°ì²´ë¥¼ ì¶œë ¥í•´ ì£¼ì„¸ìš”. ì¶œë ¥ ì‹œ ë”°ì˜´í‘œ(â€œ)ì™€ ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì(\)ë¥¼ ì •í™•íˆ ì§€ì¼œì•¼ í•˜ë©°, ë¶ˆí•„ìš”í•œ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ê³  ì˜¤ë¡œì§€ JSON ê°ì²´ë§Œ ë°˜í™˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
        """
        structured_llm = llm.with_structured_output(NewQuestionResponse)
        response = await structured_llm.ainvoke([HumanMessage(content=json_prompt)])
        return response

    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"ì˜¤ë¥˜ íƒ€ì…: {type(e)}")
        print(f"ì˜¤ë¥˜ ìƒì„¸ ì •ë³´ (Traceback): \n{traceback.format_exc()}")

        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e),
        )

# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
# ì§ˆì˜ì‘ë‹µ api
# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
class QARequest(BaseModel):
    query: str = Field(..., example="í•¨ìˆ˜ì˜ ê·¹í•œì´ë€ ë¬´ì—‡ì¸ê°€ìš”?")

class QAResponse(BaseModel):
    answer: str

@app.post(
    "/qna",
    response_model=QAResponse,
    summary="ì‚¬ìš©ì ì§ˆì˜ì‘ë‹µ",
    status_code=status.HTTP_200_OK,
)
async def answer_query(payload: QARequest):
    """
    ì‚¬ìš©ìë¡œë¶€í„° ë°›ì€ ì§ˆì˜ë¥¼ AI ê·¸ë˜í”„ì— ì „ë‹¬í•´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        result = process_query(payload.query)
        return QAResponse(answer=result)
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e),
        )

# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
# ì§ˆì˜ì‘ë‹µ + ì œëª© api
# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
class QATResponse(BaseModel):
    answer: str
    title: str

@app.post(
    "/qnantitle",
    response_model=QATResponse,
    summary="ì‚¬ìš©ì ì§ˆì˜ì‘ë‹µ",
    status_code=status.HTTP_200_OK,
)
async def answer_query(payload: QARequest):
    """
    ì‚¬ìš©ìë¡œë¶€í„° ë°›ì€ ì§ˆì˜ë¥¼ AI ê·¸ë˜í”„ì— ì „ë‹¬í•´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        result = process_query(payload.query)
        prompt = f"""System:
        ë‹¹ì‹ ì€ â€˜ì±„íŒ…ë°© ì œëª© ìƒì„±ê¸°(Chat Title Generator)â€™ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìê°€ ë³´ë‚¸ ë©”ì‹œì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„, ê·¸ ë©”ì‹œì§€ì˜ í•µì‹¬ ì£¼ì œë¥¼ 3~6ê°œì˜ ë‹¨ì–´ë¡œ ìš”ì•½í•œ ì§§ê³  ëª…í™•í•œ ì œëª©ì„ ì¶œë ¥í•˜ì„¸ìš”.
        â€¢ ì œëª©ì—ëŠ” ë¶ˆí•„ìš”í•œ ì¡°ì‚¬ë‚˜ ì ‘ì†ì‚¬ë¥¼ ì“°ì§€ ë§ˆì„¸ìš”.
        â€¢ êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë¥¼ í¬í•¨í•´ ëŒ€í™” ë‚´ìš©ì„ í•œëˆˆì— ì•Œ ìˆ˜ ìˆê²Œ ì‘ì„±í•˜ì„¸ìš”.
        â€¢ ì¶œë ¥ í˜•ì‹ì€ **ì œëª©** í…ìŠ¤íŠ¸ë§Œ, ë”°ì˜´í‘œë‚˜ ì¶”ê°€ ì„¤ëª… ì—†ì´ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

        User:
        {payload.query}"""


        response = await llm.agenerate([[HumanMessage(content=prompt)]])
        tit = response.generations[0][0].text.strip()
        print("***** tit = ", tit)

        return QATResponse(answer=result, title=tit)
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e),
        )


# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
# ì§ˆì˜ì‘ë‹µ ì´ë¯¸ì§€ + ë¬¸ì api
# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
class QAImageRequest(BaseModel):
    query: str = Field(..., example="í•¨ìˆ˜ì˜ ê·¹í•œì´ë€ ë¬´ì—‡ì¸ê°€ìš”?")
    image_base64: str = Field(
        ...,
        description="data:image/png;base64, ë¡œ ì‹œì‘í•˜ëŠ” Base64 ì¸ì½”ë”© ì´ë¯¸ì§€ ë¬¸ìì—´",
        example="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA..."
    )

@app.post(
    "/qnaimg",
    response_model=QAResponse,
    summary="ì‚¬ìš©ì ì§ˆì˜ì‘ë‹µ",
    status_code=status.HTTP_200_OK,
)
async def answer_query(payload: QAImageRequest):
    try:


        # 3) ì§ˆì˜ + ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ê·¸ë˜í”„ ìƒíƒœì— ì‚½ì…
        state = {
            "messages": [
                HumanMessage(
                    content=[
                        {
                            "type": "text",
                            "text": ""
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": payload.image_base64
                            }
                        }
                    ],
                    name="User"
                )
            ]
        }

        for step in graph.stream(state, config=config):
            if step:
                node_name = list(step.keys())[0]
                print(f"ğŸ”„ ì‹¤í–‰ ì¤‘: {node_name}")

        final_state = graph.get_state(config=config)
        messages = final_state.values['messages']

        ai_messages = [msg for msg in messages if isinstance(msg, AIMessage)]
        if ai_messages:
            final_message = ai_messages[-1].content
        else:
            final_message = messages[-1].content if messages else "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        return QAResponse(answer=final_message)
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e),
        )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app",host="0.0.0.0", port=8000, reload=True, log_level="debug")
