"""
EMA (Engineering Mathematics Assistant) ë©”ì¸ ì‹¤í–‰ íŒŒì¼
"""
import os
import sys
import uuid
import warnings
from typing import Dict, Any
from langchain_core.messages import HumanMessage, AIMessage
from workflow import graph
from langchain_core.runnables import RunnableConfig

warnings.filterwarnings("ignore", message="Convert_system_message_to_human will be deprecated!")

# ì„¤ì •
config = RunnableConfig(
    recursion_limit=10, 
    configurable={"thread_id": str(uuid.uuid4())}
)

def process_query(query: str) -> str:
    """
    ì‚¬ìš©ì ì§ˆì˜ë¥¼ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        query (str): ì‚¬ìš©ìì˜ ì§ˆì˜
        
    Returns:
        str: ì‹œìŠ¤í…œì˜ ì‘ë‹µ
    """
    print(f"ì‚¬ìš©ì ì§ˆì˜ ì²˜ë¦¬ ì‹œì‘: {query}")
    
    state = {"messages": [HumanMessage(content=query, name="User")]}
    
    try:
        for step in graph.stream(state, config=config):
            if step:
                node_name = list(step.keys())[0]
                print(f"ğŸ”„ ì‹¤í–‰ ì¤‘: {node_name}")
        
        final_state = graph.get_state(config=config)
        messages = final_state.values['messages']
        
        ai_messages = [msg for msg in messages if isinstance(msg, AIMessage)]
        if ai_messages:
            final_message = ai_messages[-1].content
        else:
            final_message = messages[-1].content if messages else "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        return final_message
        
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
    query = "í¸ë¯¸ë¶„ ë¬¸ì œ í•˜ë‚˜ ë§Œë“¤ì–´ì£¼ì„¸ìš”"
    response = process_query(query)
    
    print("\n" + "=" * 50)
    print("EMAì˜ ì‘ë‹µ:")
    print("=" * 50)
    print(response)
    print("=" * 50)

if __name__ == "__main__":
    main()