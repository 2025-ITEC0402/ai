{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-10T05:58:44.877041Z",
     "start_time": "2025-05-10T05:58:44.867928Z"
    }
   },
   "source": [
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from typing_extensions import override\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv(override=True)\n",
    "print(\"ğŸ” PROJECT:\", os.getenv(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "print(\"ğŸ” CREDENTIAL FILE:\", os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\"))\n",
    "# âœ… ì¶”ê°€: vertexai ì´ˆê¸°í™” (í”„ë¡œì íŠ¸ ê°•ì œ ì ìš©)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” PROJECT: knu-ema\n",
      "ğŸ” CREDENTIAL FILE: C:/Users/SAMSUNG/AppData/Roaming/gcloud/knu-ema-af3cd6fa4532.json\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T06:00:33.872162Z",
     "start_time": "2025-05-10T05:58:47.210150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# 1. PDF íŒŒì¼ ë¡œë“œ\n",
    "loader = PyPDFLoader(\"James Stewart - Calculus, Early Transcendentals, International Metric Edition-CENGAGE Learning (2016).pdf\")\n",
    "\n",
    "# 2. í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150\n",
    ")\n",
    "\n",
    "# 3. ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• \n",
    "docs = loader.load()\n",
    "split_docs = text_splitter.split_documents(docs)\n"
   ],
   "id": "f7c94cdaa252e0e7",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T06:01:33.559126Z",
     "start_time": "2025-05-10T06:01:30.770974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. ë°°ì¹˜ ì„ë² ë”©ìš© ë˜í¼ í´ë˜ìŠ¤ ì •ì˜\n",
    "import time\n",
    "from typing import List, Sequence\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "class BatchedEmbeddings:\n",
    "    def __init__(self, base: GoogleGenerativeAIEmbeddings, batch_size: int = 16):\n",
    "        self.base = base\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __call__(self, text_or_texts):\n",
    "        # ì¸í’‹ì´ str ì´ë©´ embed_query, list ë©´ embed_documents ë¡œ ë¶„ê¸°\n",
    "        if isinstance(text_or_texts, str):\n",
    "            return self.embed_query(text_or_texts)\n",
    "        return self.embed_documents(text_or_texts)\n",
    "\n",
    "    def embed_documents(self, texts: Sequence[str]) -> List[List[float]]:\n",
    "        all_embeddings: List[List[float]] = []\n",
    "        for i in range(0, len(texts), self.batch_size):\n",
    "            batch = texts[i : i + self.batch_size]\n",
    "            embs = self.base.embed_documents(batch)\n",
    "            all_embeddings.extend(embs)\n",
    "            if i + self.batch_size < len(texts):\n",
    "                print(\"sleep \", i)\n",
    "                time.sleep(32)\n",
    "\n",
    "        return all_embeddings\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        # Retriever ì¿¼ë¦¬ìš©ì—ë„ ë°°ì¹˜ê°€ í•„ìš” ì—†ìœ¼ë‹ˆ ë°”ë¡œ ìœ„ì„\n",
    "        return self.base.embed_query(text)\n"
   ],
   "id": "fb6ac75f361c4563",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T10:53:16.489187Z",
     "start_time": "2025-05-09T07:46:26.107540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Batched Embeddings ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "base_embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/gemini-embedding-exp-03-07\"\n",
    ")\n",
    "embeddings = BatchedEmbeddings(\n",
    "    base=base_embeddings,\n",
    "    batch_size=16  # í•„ìš”ì— ë”°ë¼ ì¡°ì ˆí•˜ì„¸ìš”\n",
    ")\n",
    "\n",
    "# 6. FAISS VectorStore ìƒì„± (ë‚´ë¶€ì—ì„œ batch ë‹¨ìœ„ë¡œ ì„ë² ë”© ì²˜ë¦¬)\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "# 7. Retriever ìƒì„± ë° í™•ì¸\n",
    "calculus_retriever = vectorstore.as_retriever()\n",
    "print(f\"ì´ ì²­í¬ ìˆ˜: {len(split_docs)}\")\n",
    "print(f\"ì²« ì²­í¬ ë¯¸ë¦¬ë³´ê¸°:\\n{split_docs[0].page_content[:300]}\")"
   ],
   "id": "101c0628656ad64a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep  0\n",
      "sleep  16\n",
      "sleep  32\n",
      "sleep  48\n",
      "sleep  64\n",
      "sleep  80\n",
      "sleep  96\n",
      "sleep  112\n",
      "sleep  128\n",
      "sleep  144\n",
      "sleep  160\n",
      "sleep  176\n",
      "sleep  192\n",
      "sleep  208\n",
      "sleep  224\n",
      "sleep  240\n",
      "sleep  256\n",
      "sleep  272\n",
      "sleep  288\n",
      "sleep  304\n",
      "sleep  320\n",
      "sleep  336\n",
      "sleep  352\n",
      "sleep  368\n",
      "sleep  384\n",
      "sleep  400\n",
      "sleep  416\n",
      "sleep  432\n",
      "sleep  448\n",
      "sleep  464\n",
      "sleep  480\n",
      "sleep  496\n",
      "sleep  512\n",
      "sleep  528\n",
      "sleep  544\n",
      "sleep  560\n",
      "sleep  576\n",
      "sleep  592\n",
      "sleep  608\n",
      "sleep  624\n",
      "sleep  640\n",
      "sleep  656\n",
      "sleep  672\n",
      "sleep  688\n",
      "sleep  704\n",
      "sleep  720\n",
      "sleep  736\n",
      "sleep  752\n",
      "sleep  768\n",
      "sleep  784\n",
      "sleep  800\n",
      "sleep  816\n",
      "sleep  832\n",
      "sleep  848\n",
      "sleep  864\n",
      "sleep  880\n",
      "sleep  896\n",
      "sleep  912\n",
      "sleep  928\n",
      "sleep  944\n",
      "sleep  960\n",
      "sleep  976\n",
      "sleep  992\n",
      "sleep  1008\n",
      "sleep  1024\n",
      "sleep  1040\n",
      "sleep  1056\n",
      "sleep  1072\n",
      "sleep  1088\n",
      "sleep  1104\n",
      "sleep  1120\n",
      "sleep  1136\n",
      "sleep  1152\n",
      "sleep  1168\n",
      "sleep  1184\n",
      "sleep  1200\n",
      "sleep  1216\n",
      "sleep  1232\n",
      "sleep  1248\n",
      "sleep  1264\n",
      "sleep  1280\n",
      "sleep  1296\n",
      "sleep  1312\n",
      "sleep  1328\n",
      "sleep  1344\n",
      "sleep  1360\n",
      "sleep  1376\n",
      "sleep  1392\n",
      "sleep  1408\n",
      "sleep  1424\n",
      "sleep  1440\n",
      "sleep  1456\n",
      "sleep  1472\n",
      "sleep  1488\n",
      "sleep  1504\n",
      "sleep  1520\n",
      "sleep  1536\n",
      "sleep  1552\n",
      "sleep  1568\n",
      "sleep  1584\n",
      "sleep  1600\n",
      "sleep  1616\n",
      "sleep  1632\n",
      "sleep  1648\n",
      "sleep  1664\n",
      "sleep  1680\n",
      "sleep  1696\n",
      "sleep  1712\n",
      "sleep  1728\n",
      "sleep  1744\n",
      "sleep  1760\n",
      "sleep  1776\n",
      "sleep  1792\n",
      "sleep  1808\n",
      "sleep  1824\n",
      "sleep  1840\n",
      "sleep  1856\n",
      "sleep  1872\n",
      "sleep  1888\n",
      "sleep  1904\n",
      "sleep  1920\n",
      "sleep  1936\n",
      "sleep  1952\n",
      "sleep  1968\n",
      "sleep  1984\n",
      "sleep  2000\n",
      "sleep  2016\n",
      "sleep  2032\n",
      "sleep  2048\n",
      "sleep  2064\n",
      "sleep  2080\n",
      "sleep  2096\n",
      "sleep  2112\n",
      "sleep  2128\n",
      "sleep  2144\n",
      "sleep  2160\n",
      "sleep  2176\n",
      "sleep  2192\n",
      "sleep  2208\n",
      "sleep  2224\n",
      "sleep  2240\n",
      "sleep  2256\n",
      "sleep  2272\n",
      "sleep  2288\n",
      "sleep  2304\n",
      "sleep  2320\n",
      "sleep  2336\n",
      "sleep  2352\n",
      "sleep  2368\n",
      "sleep  2384\n",
      "sleep  2400\n",
      "sleep  2416\n",
      "sleep  2432\n",
      "sleep  2448\n",
      "sleep  2464\n",
      "sleep  2480\n",
      "sleep  2496\n",
      "sleep  2512\n",
      "sleep  2528\n",
      "sleep  2544\n",
      "sleep  2560\n",
      "sleep  2576\n",
      "sleep  2592\n",
      "sleep  2608\n",
      "sleep  2624\n",
      "sleep  2640\n",
      "sleep  2656\n",
      "sleep  2672\n",
      "sleep  2688\n",
      "sleep  2704\n",
      "sleep  2720\n",
      "sleep  2736\n",
      "sleep  2752\n",
      "sleep  2768\n",
      "sleep  2784\n",
      "sleep  2800\n",
      "sleep  2816\n",
      "sleep  2832\n",
      "sleep  2848\n",
      "sleep  2864\n",
      "sleep  2880\n",
      "sleep  2896\n",
      "sleep  2912\n",
      "sleep  2928\n",
      "sleep  2944\n",
      "sleep  2960\n",
      "sleep  2976\n",
      "sleep  2992\n",
      "sleep  3008\n",
      "sleep  3024\n",
      "sleep  3040\n",
      "sleep  3056\n",
      "sleep  3072\n",
      "sleep  3088\n",
      "sleep  3104\n",
      "sleep  3120\n",
      "sleep  3136\n",
      "sleep  3152\n",
      "sleep  3168\n",
      "sleep  3184\n",
      "sleep  3200\n",
      "sleep  3216\n",
      "sleep  3232\n",
      "sleep  3248\n",
      "sleep  3264\n",
      "sleep  3280\n",
      "sleep  3296\n",
      "sleep  3312\n",
      "sleep  3328\n",
      "sleep  3344\n",
      "sleep  3360\n",
      "sleep  3376\n",
      "sleep  3392\n",
      "sleep  3408\n",
      "sleep  3424\n",
      "sleep  3440\n",
      "sleep  3456\n",
      "sleep  3472\n",
      "sleep  3488\n",
      "sleep  3504\n",
      "sleep  3520\n",
      "sleep  3536\n",
      "sleep  3552\n",
      "sleep  3568\n",
      "sleep  3584\n",
      "sleep  3600\n",
      "sleep  3616\n",
      "sleep  3632\n",
      "sleep  3648\n",
      "sleep  3664\n",
      "sleep  3680\n",
      "sleep  3696\n",
      "sleep  3712\n",
      "sleep  3728\n",
      "sleep  3744\n",
      "sleep  3760\n",
      "sleep  3776\n",
      "sleep  3792\n",
      "sleep  3808\n",
      "sleep  3824\n",
      "sleep  3840\n",
      "sleep  3856\n",
      "sleep  3872\n",
      "sleep  3888\n",
      "sleep  3904\n",
      "sleep  3920\n",
      "sleep  3936\n",
      "sleep  3952\n",
      "sleep  3968\n",
      "sleep  3984\n",
      "sleep  4000\n",
      "sleep  4016\n",
      "sleep  4032\n",
      "sleep  4048\n",
      "sleep  4064\n",
      "sleep  4080\n",
      "sleep  4096\n",
      "sleep  4112\n",
      "sleep  4128\n",
      "sleep  4144\n",
      "sleep  4160\n",
      "sleep  4176\n",
      "sleep  4192\n",
      "sleep  4208\n",
      "sleep  4224\n",
      "sleep  4240\n",
      "sleep  4256\n",
      "sleep  4272\n",
      "sleep  4288\n",
      "sleep  4304\n",
      "sleep  4320\n",
      "sleep  4336\n",
      "sleep  4352\n",
      "sleep  4368\n",
      "sleep  4384\n",
      "sleep  4400\n",
      "sleep  4416\n",
      "sleep  4432\n",
      "sleep  4448\n",
      "sleep  4464\n",
      "sleep  4480\n",
      "sleep  4496\n",
      "sleep  4512\n",
      "sleep  4528\n",
      "sleep  4544\n",
      "sleep  4560\n",
      "sleep  4576\n",
      "sleep  4592\n",
      "sleep  4608\n",
      "sleep  4624\n",
      "sleep  4640\n",
      "sleep  4656\n",
      "sleep  4672\n",
      "sleep  4688\n",
      "sleep  4704\n",
      "sleep  4720\n",
      "sleep  4736\n",
      "sleep  4752\n",
      "sleep  4768\n",
      "sleep  4784\n",
      "sleep  4800\n",
      "sleep  4816\n",
      "sleep  4832\n",
      "sleep  4848\n",
      "sleep  4864\n",
      "sleep  4880\n",
      "sleep  4896\n",
      "sleep  4912\n",
      "sleep  4928\n",
      "sleep  4944\n",
      "sleep  4960\n",
      "sleep  4976\n",
      "sleep  4992\n",
      "sleep  5008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì²­í¬ ìˆ˜: 5028\n",
      "ì²« ì²­í¬ ë¯¸ë¦¬ë³´ê¸°:\n",
      "calculus\n",
      "Early Transc EndEnTals\n",
      "Eigh Th EdiTion\n",
      "mETric v Ersion\n",
      "Jam Es sTE war T\n",
      "McMaster University  \n",
      "and  \n",
      "University of toronto\n",
      "Australia â€¢ Brazil â€¢ Mexico â€¢ Singapore â€¢ United Kingdom â€¢ United States\n",
      "Copyright 2016 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated,\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "vectorstore.save_local(\"vectorstore\")",
   "id": "a37a8e1211c4226c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T06:23:19.725065Z",
     "start_time": "2025-05-10T06:23:19.652233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Batched Embeddings ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "base_embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/gemini-embedding-exp-03-07\"\n",
    ")\n",
    "\n",
    "# 6. FAISS VectorStore ìƒì„± (ë‚´ë¶€ì—ì„œ batch ë‹¨ìœ„ë¡œ ì„ë² ë”© ì²˜ë¦¬)\n",
    "vectorstore = FAISS.load_local(\"vectorstore\", base_embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# 7. Retriever ìƒì„± ë° í™•ì¸\n",
    "calculus_retriever = vectorstore.as_retriever()"
   ],
   "id": "9672e945485f6b4c",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T15:19:08.025893Z",
     "start_time": "2025-05-09T15:19:06.745431Z"
    }
   },
   "cell_type": "code",
   "source": "calculus_retriever.invoke(\"WHAT IS INTEGRAL\")",
   "id": "f897672121915571",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='8f2d5f76-c7a3-4e4b-b3d4-509cf0add101', metadata={'producer': 'Pdftools SDK', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-05-01T06:05:37+00:00', 'source': 'James Stewart - Calculus, Early Transcendentals, International Metric Edition-CENGAGE Learning (2016).pdf', 'total_pages': 1421, 'page': 409, 'page_label': '410'}, page_content='we divide the interval fa, bg into n subintervals of equal width Dxâˆ’sb2adyn. \\nWe\\xa0let x0 sâˆ’ ad, x1, x2, . . . , x n sâˆ’bd be the endpoints of these subintervals and we \\nlet x1*, x2*, . . . , x n* be any sample points in these subintervals, so xi* lies in the ith \\nsubinterval fxi21, xig. Then the definite integral of f from a to b is\\nyb\\na fsxddxâˆ’lim\\nn l ` on\\niâˆ’1 fsxi*dDx\\n provided that this limit exists and gives the same value for all possible choices of sample points. If it does exist, we say that \\nf is integrable on fa, bg.\\nThe precise meaning of the limit that defines the integral is as follows:\\nFor every number Â« . 0 there is an integer N such that\\nZyb\\na fsxddx2on\\niâˆ’1 fsxi*dDx Z, Â«\\nfor every integer n.N and for every choice of xi* in fxi21, xig.\\nNote 1  The symbol y was introduced by Leibniz and is called an integral sign. It \\nis an elongated S and was chosen because an integral is a limit of sums. In the notation 1\\x03'),\n",
       " Document(id='efb300a2-aa51-474e-9c43-557dac39015d', metadata={'producer': 'Pdftools SDK', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-05-01T06:05:37+00:00', 'source': 'James Stewart - Calculus, Early Transcendentals, International Metric Edition-CENGAGE Learning (2016).pdf', 'total_pages': 1421, 'page': 410, 'page_label': '411'}, page_content='SeCtION  5.2  The Definite Integral  379\\n yb\\na fsxddx, fsxd is called the integrand and a and b are called the limits of integration; \\na is the lower limit and b is the upper limit. For now, the symbol dx has no meaning by \\nitself; yb\\na fsxddx is all one symbol. The dx simply indicates that the independent vari  able \\nis x. The procedure of calculating an integral is called integration.\\nNote 2  The definite integral yb\\na fsxddx is a number; it does not depend on x. In fact, \\nwe could use any letter in place of x without changing the value of the integral:\\nyb\\na fsxddxâˆ’yb\\na fstddtâˆ’yb\\na fsrddr\\nNote 3  The sum\\non\\niâˆ’1 fsxi*dDx\\nthat occurs in Definition 2 is called a Riemann sum after the German mathematician \\nBernhard Riemann (1826  â€“1866). So Definition 2 says that the definite integral of an \\nintegrable function can be approximated to within any desired degree of accuracy by a Riemann sum.\\nWe know that if \\nf happens to be positive, then the Riemann sum can be interpreted'),\n",
       " Document(id='08e680d3-9b30-4ad1-a49d-160d159d460d', metadata={'producer': 'Pdftools SDK', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-05-01T06:05:37+00:00', 'source': 'James Stewart - Calculus, Early Transcendentals, International Metric Edition-CENGAGE Learning (2016).pdf', 'total_pages': 1421, 'page': 1358, 'page_label': '1359'}, page_content='1056, 1058, 1059\\ncomparison properties of, 387conversion to cylindrical  \\ncoordinates, 1040\\nconversion to polar coordinates, 1012conversion to spherical  \\ncoordinates, 1046\\ndefinite, 378, 988derivative of, 394double ( see double integral)\\nevaluating, 381improper, 527indefinite, 402iterated, 993line ( see line integral)\\npatterns in, 513properties of, 385surface, 1122, 1129of symmetric functions, 417table of, 471, 503, 509, rp 6â€“10\\ntriple, 1029, 1030units for, 408\\nintegral calculus, 2, 3Integral Test, 721integrand, 379\\ndiscontinuous, 531\\nintegration, 379\\napproximate, 514by computer algebra system, 511of exponential functions, 383, 413formulas, 471, 503, rp 6â€“10\\nindefinite, 402limits of, 379numerical, 514partial, 993, 995by partial fractions, 493by parts, 472, 473, 474of a power series, 754of rational functions, 493by a rationalizing substitution, 500reversing order of, 995, 1006over a solid, 1042substitution in, 412tables, use of, 508term-by-term, 754of a vector function, 859'),\n",
       " Document(id='b23cd204-6816-4ced-bfed-b394b89e615d', metadata={'producer': 'Pdftools SDK', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-05-01T06:05:37+00:00', 'source': 'James Stewart - Calculus, Early Transcendentals, International Metric Edition-CENGAGE Learning (2016).pdf', 'total_pages': 1421, 'page': 1392, 'page_label': '1393'}, page_content='what are the units for the integral?\\n   y6\\n0 fsxddx represents the amount of work done. Its units are \\nnewton-meters, or joules.\\n 6. (a)  What is the average value of a function f on an  \\ninterval fa, bg?\\n   faveâˆ’1\\nb2a yb\\na fsxddx\\n  (b)  What does the Mean Value Theorem for Integrals say? What is its geometric interpretation?\\n    If f is continuous on fa, bg, then there is a number c in \\nfa, bg at which the value of f is exactly equal to the aver -\\nage value of the function, that is, fscdâˆ’fave. This means \\nthat for positive functions f, there is a number c such that \\nthe rectangle with base fa, bg and height fscd has the same \\narea as the region under the graph of f from a to b. 1. (a)  Draw two typical curves yâˆ’fsxd and yâˆ’tsxd, where \\nfsxd>tsxd for a<x<b. Show how to approximate the \\narea between these curves by a Riemann sum and sketch the corresponding approximating rectangles. Then write an expression for the exact area.\\n   bf(xi*)\\nf(xi*)-g(xi*)y=f(x)\\ny=g(x)\\n0a\\n_g(xi*)\\nxi*\\nÃxxy')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T06:01:43.008364Z",
     "start_time": "2025-05-10T06:01:42.985541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# 1) ì „ì²´ ì±•í„° MD íŒŒì¼ì„ ë¡œë“œ\n",
    "loader = DirectoryLoader(\n",
    "    path=\"chapters_md\", glob=\"*.md\", loader_cls=TextLoader\n",
    ")\n",
    "md_docs = loader.load()\n",
    "\n",
    "len(md_docs)\n",
    "md_docs[0]"
   ],
   "id": "d7aa81cd2ed5a0f7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'chapters_md\\\\Chapter 01 Functions and Models.md'}, page_content='# Chapter 01 Functions and Models\\n\\n# í•¨ìˆ˜ì™€ ì—­í•¨ìˆ˜\\n\\n## í•¨ìˆ˜ì˜ ë³€í™˜\\n\\në‹¤ìŒì€ í•¨ìˆ˜ ê·¸ë˜í”„ì˜ ë³€í™˜ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤.  ğŸ˜€\\n\\n* yì¶• ëŒ€ì¹­: $$y = f(-x)$$\\n* xì¶• ëŒ€ì¹­: $$y = -f(x)$$\\n* yì¶• ë°©í–¥ìœ¼ë¡œ 2ë°° í™•ëŒ€: $$y = 2f(x)$$\\n* yì¶• ë°©í–¥ìœ¼ë¡œ 1/2ë°° ì¶•ì†Œ: $$y = \\\\frac{1}{2}f(x)$$\\n* xì¶• ë°©í–¥ìœ¼ë¡œ 2ë°° í™•ëŒ€: $$y = f(\\\\frac{1}{2}x)$$\\n* xì¶• ë°©í–¥ìœ¼ë¡œ 1/2ë°° ì¶•ì†Œ: $$y = f(2x)$$\\n\\n\\n## ì¼ëŒ€ì¼ í•¨ìˆ˜ì™€ ì—­í•¨ìˆ˜\\n\\n### ì¼ëŒ€ì¼ í•¨ìˆ˜\\n\\n* **ì •ì˜:** í•¨ìˆ˜ fê°€ ì¼ëŒ€ì¼ í•¨ìˆ˜ë¼ëŠ” ê²ƒì€ ì„œë¡œ ë‹¤ë¥¸ ì…ë ¥ê°’ì— ëŒ€í•´ í•­ìƒ ì„œë¡œ ë‹¤ë¥¸ ì¶œë ¥ê°’ì„ ê°–ëŠ”ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.  ì¦‰, $$x_1 \\\\ne x_2$$ ì´ë©´ $$f(x_1) \\\\ne f(x_2)$$ ì…ë‹ˆë‹¤. ğŸ¤”\\n* **ìˆ˜í‰ì„  ê²€ì •:** ê·¸ë˜í”„ì—ì„œ í•¨ìˆ˜ê°€ ì¼ëŒ€ì¼ í•¨ìˆ˜ì¸ì§€ í™•ì¸í•˜ëŠ” ë°©ë²•ì€ ìˆ˜í‰ì„  ê²€ì •ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.  ì–´ë–¤ ìˆ˜í‰ì„ ë„ ê·¸ë˜í”„ì™€ ë‘ ì  ì´ìƒì—ì„œ êµì°¨í•˜ì§€ ì•Šìœ¼ë©´ í•´ë‹¹ í•¨ìˆ˜ëŠ” ì¼ëŒ€ì¼ í•¨ìˆ˜ì…ë‹ˆë‹¤.\\n\\n\\n### ì—­í•¨ìˆ˜\\n\\n* **ì •ì˜:**  ì¼ëŒ€ì¼ í•¨ìˆ˜ $$f$$ì˜ ì •ì˜ì—­ì´ Aì´ê³  ì¹˜ì—­ì´ Bì¼ ë•Œ, ì—­í•¨ìˆ˜ $$f^{-1}$$ëŠ” ì •ì˜ì—­ì´ Bì´ê³  ì¹˜ì—­ì´ Aì´ë©°, ëª¨ë“  $$y \\\\in B$$ì— ëŒ€í•´ $$f^{-1}(y) = x \\\\Leftrightarrow f(x) = y$$ ë¡œ ì •ì˜ë©ë‹ˆë‹¤. ğŸ”„\\n* **ê·¸ë˜í”„:** $$f^{-1}$$ì˜ ê·¸ë˜í”„ëŠ” $$f$$ì˜ ê·¸ë˜í”„ë¥¼ ì§ì„  $$y=x$$ì— ëŒ€í•´ ëŒ€ì¹­ì‹œì¼œ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n\\n## ì—­ì‚¼ê°í•¨ìˆ˜\\n\\n### ì—­ì‚¬ì¸ í•¨ìˆ˜\\n\\n* **ì •ì˜:** ì—­ì‚¬ì¸ í•¨ìˆ˜ $$f(x) = \\\\sin^{-1}x$$ ëŠ” $$\\\\sin y = x$$ ì´ê³  $$-\\\\frac{\\\\pi}{2} \\\\le y \\\\le \\\\frac{\\\\pi}{2}$$ ë¥¼ ë§Œì¡±í•˜ëŠ” y ê°’ìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤.\\n* **ì •ì˜ì—­:** $$-1 \\\\le x \\\\le 1$$\\n* **ì¹˜ì—­:** $$-\\\\frac{\\\\pi}{2} \\\\le y \\\\le \\\\frac{\\\\pi}{2}$$\\n\\n\\n### ì—­ì½”ì‚¬ì¸ í•¨ìˆ˜\\n\\n* **ì •ì˜:** ì—­ì½”ì‚¬ì¸ í•¨ìˆ˜ $$f(x) = \\\\cos^{-1}x$$ ëŠ” $$\\\\cos y = x$$ ì´ê³  $$0 \\\\le y \\\\le \\\\pi$$ ë¥¼ ë§Œì¡±í•˜ëŠ” y ê°’ìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤.\\n* **ì •ì˜ì—­:** $$-1 \\\\le x \\\\le 1$$\\n* **ì¹˜ì—­:** $$0 \\\\le y \\\\le \\\\pi$$\\n\\n\\n## í•©ì„±í•¨ìˆ˜ì™€ ì •ì˜ì—­\\n\\n* **í•©ì„±í•¨ìˆ˜ì˜ ì •ì˜:** ë‘ í•¨ìˆ˜ fì™€ tì˜ í•©ì„±í•¨ìˆ˜ëŠ” $$(f \\\\circ t)(x) = f(t(x))$$ ë¡œ ì •ì˜ë©ë‹ˆë‹¤. ğŸ“Œ\\n* **í•©ì„±í•¨ìˆ˜ì˜ ì •ì˜ì—­:** fì™€ tì˜ í•©ì„±í•¨ìˆ˜ì˜ ì •ì˜ì—­ì€ tì˜ ì •ì˜ì—­ê³¼ fì˜ ì •ì˜ì—­ì˜ êµì§‘í•© ì¤‘ì—ì„œ t(x)ê°€ fì˜ ì •ì˜ì—­ì— í¬í•¨ë˜ëŠ” xì˜ ì§‘í•©ì…ë‹ˆë‹¤.  ì¦‰,  $$ \\\\{ x | x \\\\in (A \\\\cap B) \\\\text{ and } t(x) \\\\in A \\\\}$$ ì…ë‹ˆë‹¤. (AëŠ” fì˜ ì •ì˜ì—­, BëŠ” tì˜ ì •ì˜ì—­)\\n\\n\\n## í•¨ìˆ˜ì˜ ê³±ê³¼ ì •ì˜ì—­\\n\\n* í•¨ìˆ˜ fì™€ tì˜ ê³± ftì˜ ì •ì˜ì—­ì€ ë‘ í•¨ìˆ˜ì˜ ì •ì˜ì—­ì˜ êµì§‘í•©, ì¦‰ $$A \\\\cap B$$ ì…ë‹ˆë‹¤.\\n* í•¨ìˆ˜ f/tì˜ ì •ì˜ì—­ì€ $$A \\\\cap B$$ ì—ì„œ $$t(x) = 0$$ ì¸ xë¥¼ ì œì™¸í•œ ì§‘í•©ì…ë‹ˆë‹¤.\\n\\n\\n# í•¨ìˆ˜ì™€ ê·¸ë˜í”„ ğŸ“ˆ\\n\\n## ì—­í•¨ìˆ˜ì™€ ë³€í™˜ ğŸ”„\\n\\níƒ„ì  íŠ¸ í•¨ìˆ˜ì˜ ì—­í•¨ìˆ˜ì™€ ê·¸ë˜í”„ì˜ ì´ë™, ë°˜ì‚¬ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤.  \\n\\n### ì—­ íƒ„ì  íŠ¸ í•¨ìˆ˜\\n\\nì—­ íƒ„ì  íŠ¸ í•¨ìˆ˜ $f(x) = \\\\tan^{-1}x$ ëŠ” $\\\\tan y = x$ ì´ê³  $-\\\\frac{\\\\pi}{2} < y < \\\\frac{\\\\pi}{2}$ ë¥¼ ë§Œì¡±í•˜ëŠ” í•¨ìˆ˜ë¡œ ì •ì˜ë©ë‹ˆë‹¤. ğŸ¤”\\n\\nì •ì˜ì—­ì€ ëª¨ë“  ì‹¤ìˆ˜($\\\\mathbb{R}$)ì´ê³ , ì¹˜ì—­ì€ $-\\\\frac{\\\\pi}{2} < y < \\\\frac{\\\\pi}{2}$ ì…ë‹ˆë‹¤.\\n\\n### ê·¸ë˜í”„ ë³€í™˜\\n\\ní•¨ìˆ˜ $f(x)$ ì˜ ê·¸ë˜í”„ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n* ìœ„ë¡œ 2ë§Œí¼ ì´ë™: $y = f(x) + 2$\\n* ì•„ë˜ë¡œ 2ë§Œí¼ ì´ë™: $y = f(x) - 2$\\n* ì˜¤ë¥¸ìª½ìœ¼ë¡œ 2ë§Œí¼ ì´ë™: $y = f(x-2)$\\n* ì™¼ìª½ìœ¼ë¡œ 2ë§Œí¼ ì´ë™: $y = f(x+2)$\\n* xì¶•ì— ëŒ€í•´ ë°˜ì‚¬: $y = -f(x)$\\n\\n\\n## ê·¹í•œ â¡ï¸\\n\\ní•¨ìˆ˜ì˜ ê·¹í•œì— ëŒ€í•œ ì„¤ëª…ê³¼ ê·¹í•œì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤.\\n\\n### ê·¹í•œì˜ ì˜ë¯¸\\n\\n* $\\\\lim_{x \\\\to a} f(x) = L$: $x$ê°€ $a$ì— í•œì—†ì´ ê°€ê¹Œì›Œì§ˆ ë•Œ (ë‹¨, $x \\\\ne a$), $f(x)$ì˜ ê°’ì€ $L$ì— í•œì—†ì´ ê°€ê¹Œì›Œì§„ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.\\n* $\\\\lim_{x \\\\to a^+} f(x) = L$: $x$ê°€ $a$ë³´ë‹¤ í° ê°’ì„ ê°€ì§€ë©´ì„œ $a$ì— í•œì—†ì´ ê°€ê¹Œì›Œì§ˆ ë•Œ, $f(x)$ì˜ ê°’ì€ $L$ì— í•œì—†ì´ ê°€ê¹Œì›Œì§„ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. (ì˜¤ë¥¸ìª½ ê·¹í•œ)\\n* $\\\\lim_{x \\\\to a^-} f(x) = L$: $x$ê°€ $a$ë³´ë‹¤ ì‘ì€ ê°’ì„ ê°€ì§€ë©´ì„œ $a$ì— í•œì—†ì´ ê°€ê¹Œì›Œì§ˆ ë•Œ, $f(x)$ì˜ ê°’ì€ $L$ì— í•œì—†ì´ ê°€ê¹Œì›Œì§„ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. (ì™¼ìª½ ê·¹í•œ)\\n\\n\\n### ê·¹í•œì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°\\n\\nì¼ë°˜ì ìœ¼ë¡œ í•¨ìˆ˜ê°’ì´ íŠ¹ì • ê°’ìœ¼ë¡œ ìˆ˜ë ´í•˜ì§€ ì•Šì„ ë•Œ ê·¹í•œì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ğŸ™…\\u200dâ™€ï¸  ì˜ˆë¥¼ ë“¤ì–´, $x=2$ì—ì„œ ì¢Œê·¹í•œê³¼ ìš°ê·¹í•œì´ ë‹¤ë¥´ê±°ë‚˜, ë¬´í•œ ë¶ˆì—°ì†ì¸ ê²½ìš° ê·¹í•œì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\\n\\n# ê·¹í•œ (Limits)\\n\\n## ê·¹í•œ ë²•ì¹™ (Limit Laws)\\n\\në‹¤ìŒ ê·¹í•œ ë²•ì¹™ë“¤ì„ ì„¤ëª…í•©ë‹ˆë‹¤.  ğŸ“–\\n\\n* **(a) í•©ì˜ ë²•ì¹™ (Sum Law)** â•\\n    í•©ì˜ ê·¹í•œì€ ê·¹í•œì˜ í•©ê³¼ ê°™ìŠµë‹ˆë‹¤.\\n    $$ \\\\lim_{x \\\\to a} [f(x) + g(x)] = \\\\lim_{x \\\\to a} f(x) + \\\\lim_{x \\\\to a} g(x) $$\\n\\n* **(b) ì°¨ì˜ ë²•ì¹™ (Difference Law)** â–\\n    ì°¨ì˜ ê·¹í•œì€ ê·¹í•œì˜ ì°¨ì™€ ê°™ìŠµë‹ˆë‹¤.\\n    $$ \\\\lim_{x \\\\to a} [f(x) - g(x)] = \\\\lim_{x \\\\to a} f(x) - \\\\lim_{x \\\\to a} g(x) $$\\n\\n* **(c) ìƒìˆ˜ë°° ë²•ì¹™ (Constant Multiple Law)** âœ–ï¸\\n    ìƒìˆ˜ì™€ í•¨ìˆ˜ì˜ ê³±ì˜ ê·¹í•œì€ ìƒìˆ˜ì™€ í•¨ìˆ˜ì˜ ê·¹í•œì˜ ê³±ê³¼ ê°™ìŠµë‹ˆë‹¤.\\n    $$ \\\\lim_{x \\\\to a} [cf(x)] = c \\\\lim_{x \\\\to a} f(x) $$\\n\\n* **(d) ê³±ì˜ ë²•ì¹™ (Product Law)** ğŸ“\\n    ê³±ì˜ ê·¹í•œì€ ê·¹í•œì˜ ê³±ê³¼ ê°™ìŠµë‹ˆë‹¤.\\n    $$ \\\\lim_{x \\\\to a} [f(x)g(x)] = \\\\lim_{x \\\\to a} f(x) \\\\cdot \\\\lim_{x \\\\to a} g(x) $$\\n\\n* **(e) ëª«ì˜ ë²•ì¹™ (Quotient Law)** â—\\n    ë¶„ëª¨ì˜ ê·¹í•œì´ 0ì´ ì•„ë‹Œ ê²½ìš°, ëª«ì˜ ê·¹í•œì€ ê·¹í•œì˜ ëª«ê³¼ ê°™ìŠµë‹ˆë‹¤.\\n    $$ \\\\lim_{x \\\\to a} \\\\frac{f(x)}{g(x)} = \\\\frac{\\\\lim_{x \\\\to a} f(x)}{\\\\lim_{x \\\\to a} g(x)} \\\\quad \\\\text{if} \\\\quad \\\\lim_{x \\\\to a} g(x) \\\\neq 0 $$\\n\\n\\nìœ„ì˜ ë²•ì¹™ë“¤ì€ í•¨ìˆ˜ì˜ ê·¹í•œì„ ê³„ì‚°í•˜ëŠ” ë° ì¤‘ìš”í•œ ë„êµ¬ì…ë‹ˆë‹¤.  ğŸ’¡ ê° ë²•ì¹™ì€ ê·¹í•œì˜ ì„±ì§ˆì„ ë³´ì—¬ì£¼ë©°, ë³µì¡í•œ í•¨ìˆ˜ì˜ ê·¹í•œì„ ê°„ë‹¨í•œ í•¨ìˆ˜ì˜ ê·¹í•œìœ¼ë¡œ ë¶„í•´í•˜ì—¬ ê³„ì‚°í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤. ğŸ‘')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T06:01:44.899403Z",
     "start_time": "2025-05-10T06:01:44.887476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "\n",
    "# 2) í—¤ë” ë‹¨ìœ„ Splitter\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=[\n",
    "        (\"#\",   \"Header 1\"),   # ëŒ€ì œëª©\n",
    "        (\"##\",  \"Header 2\"),   # ì†Œì œëª©\n",
    "        (\"###\", \"Header 3\"),   # ì†Œì†Œì œëª©\n",
    "    ],\n",
    "    strip_headers=False    # ì²­í¬ì— í—¤ë” ë¬¸êµ¬ë¥¼ ê·¸ëŒ€ë¡œ ë‚¨ê¸¸ì§€ ì—¬ë¶€\n",
    ")\n",
    "\n",
    "chunk_size = 500  # ë¶„í• ëœ ì²­í¬ì˜ í¬ê¸°ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "chunk_overlap = 100  # ë¶„í• ëœ ì²­í¬ ê°„ì˜ ì¤‘ë³µë˜ëŠ” ë¬¸ì ìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    ")\n",
    "\n",
    "md_docs_split: list[Document] = []"
   ],
   "id": "5087177a0e38c911",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T06:01:47.170453Z",
     "start_time": "2025-05-10T06:01:47.130305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for doc in md_docs:\n",
    "    # A) í—¤ë” ë‹¨ìœ„ë¡œ split_text â†’ List[Document]\n",
    "    header_chunks = markdown_splitter.split_text(doc.page_content)\n",
    "    for hchunk in header_chunks:\n",
    "        # hchunk.page_content, hchunk.metadata ì— í—¤ë” ì •ë³´ê°€ ë‹´ê²¨ ìˆìŒ\n",
    "\n",
    "        # B) í•´ë‹¹ ì²­í¬ë¥¼ ë‹¤ì‹œ ë¬¸ì ë‹¨ìœ„ë¡œ ìë¥´ê¸° â†’ List[str]\n",
    "        sub_texts = text_splitter.split_text(hchunk.page_content)\n",
    "        for sub in sub_texts:\n",
    "            # C) ë©”íƒ€ë°ì´í„° í•©ì¹˜ê¸°\n",
    "            meta = {**doc.metadata, **hchunk.metadata}\n",
    "\n",
    "            # (ì„ íƒ) URL ë§¤í•‘: \"Chapter 05 Integrals.md\" â†’ \"05\"\n",
    "            fname    = doc.metadata[\"source\"].split(\"/\")[-1]\n",
    "            chap_num = fname.split(\" \", 2)[1].zfill(2)\n",
    "            meta[\"url\"] = f\"https://ema.com/theory/{chap_num}\"\n",
    "\n",
    "            # D) ìµœì¢… Document ìƒì„±\n",
    "            md_docs_split.append(\n",
    "                Document(page_content=sub, metadata=meta)\n",
    "            )\n"
   ],
   "id": "2564d8429afcbcf5",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T06:06:28.186480Z",
     "start_time": "2025-05-10T06:06:28.169092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ê²€ì¦ìš© ì¶œë ¥ ì½”ë“œ\n",
    "\n",
    "# ì „ì²´ ì²­í¬ ê°œìˆ˜ ì¶œë ¥\n",
    "print(f\"ì´ ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(md_docs_split)}\\n\")\n",
    "\n",
    "# ìƒìœ„ 10ê°œ ì²­í¬ë§Œ ë¯¸ë¦¬ ë³´ê¸°\n",
    "for idx, doc in enumerate(md_docs_split[:10], start=1):\n",
    "    # ë©”íƒ€ë°ì´í„°ì—ì„œ URLê³¼ í—¤ë” ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "    url = doc.metadata.get(\"url\", \"N/A\")\n",
    "    headers = {k: v for k, v in doc.metadata.items() if k.startswith(\"Header\")}\n",
    "    preview = doc.page_content.replace(\"\\n\", \" \")[:200] + \"...\"\n",
    "\n",
    "    print(f\"--- Chunk #{idx} ---\")\n",
    "    print(f\"URL       : {url}\")\n",
    "    print(f\"Headers   : {headers}\")\n",
    "    print(f\"Preview   : {preview}\")\n",
    "    print()\n"
   ],
   "id": "b6d0463725100661",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ë¶„í• ëœ ì²­í¬ ìˆ˜: 340\n",
      "\n",
      "--- Chunk #1 ---\n",
      "URL       : https://ema.com/theory/01\n",
      "Headers   : {'Header 1': 'Chapter 01 Functions and Models'}\n",
      "Preview   : # Chapter 01 Functions and Models...\n",
      "\n",
      "--- Chunk #2 ---\n",
      "URL       : https://ema.com/theory/01\n",
      "Headers   : {'Header 1': 'í•¨ìˆ˜ì™€ ì—­í•¨ìˆ˜', 'Header 2': 'í•¨ìˆ˜ì˜ ë³€í™˜'}\n",
      "Preview   : # í•¨ìˆ˜ì™€ ì—­í•¨ìˆ˜   ## í•¨ìˆ˜ì˜ ë³€í™˜   ë‹¤ìŒì€ í•¨ìˆ˜ ê·¸ë˜í”„ì˜ ë³€í™˜ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤.  ğŸ˜€   * yì¶• ëŒ€ì¹­: $$y = f(-x)$$ * xì¶• ëŒ€ì¹­: $$y = -f(x)$$ * yì¶• ë°©í–¥ìœ¼ë¡œ 2ë°° í™•ëŒ€: $$y = 2f(x)$$ * yì¶• ë°©í–¥ìœ¼ë¡œ 1/2ë°° ì¶•ì†Œ: $$y = \\frac{1}{2}f(x)$$ * xì¶• ë°©í–¥ìœ¼ë¡œ 2ë°° í™•ëŒ€: $$y = f(...\n",
      "\n",
      "--- Chunk #3 ---\n",
      "URL       : https://ema.com/theory/01\n",
      "Headers   : {'Header 1': 'í•¨ìˆ˜ì™€ ì—­í•¨ìˆ˜', 'Header 2': 'ì¼ëŒ€ì¼ í•¨ìˆ˜ì™€ ì—­í•¨ìˆ˜', 'Header 3': 'ì¼ëŒ€ì¼ í•¨ìˆ˜'}\n",
      "Preview   : ## ì¼ëŒ€ì¼ í•¨ìˆ˜ì™€ ì—­í•¨ìˆ˜   ### ì¼ëŒ€ì¼ í•¨ìˆ˜   * **ì •ì˜:** í•¨ìˆ˜ fê°€ ì¼ëŒ€ì¼ í•¨ìˆ˜ë¼ëŠ” ê²ƒì€ ì„œë¡œ ë‹¤ë¥¸ ì…ë ¥ê°’ì— ëŒ€í•´ í•­ìƒ ì„œë¡œ ë‹¤ë¥¸ ì¶œë ¥ê°’ì„ ê°–ëŠ”ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.  ì¦‰, $$x_1 \\ne x_2$$ ì´ë©´ $$f(x_1) \\ne f(x_2)$$ ì…ë‹ˆë‹¤. ğŸ¤” * **ìˆ˜í‰ì„  ê²€ì •:** ê·¸ë˜í”„ì—ì„œ í•¨ìˆ˜ê°€ ì¼ëŒ€ì¼ í•¨ìˆ˜ì¸ì§€ í™•ì¸í•˜ëŠ” ë°©ë²•ì€ ìˆ˜í‰ì„  ê²€...\n",
      "\n",
      "--- Chunk #4 ---\n",
      "URL       : https://ema.com/theory/01\n",
      "Headers   : {'Header 1': 'í•¨ìˆ˜ì™€ ì—­í•¨ìˆ˜', 'Header 2': 'ì¼ëŒ€ì¼ í•¨ìˆ˜ì™€ ì—­í•¨ìˆ˜', 'Header 3': 'ì—­í•¨ìˆ˜'}\n",
      "Preview   : ### ì—­í•¨ìˆ˜   * **ì •ì˜:**  ì¼ëŒ€ì¼ í•¨ìˆ˜ $$f$$ì˜ ì •ì˜ì—­ì´ Aì´ê³  ì¹˜ì—­ì´ Bì¼ ë•Œ, ì—­í•¨ìˆ˜ $$f^{-1}$$ëŠ” ì •ì˜ì—­ì´ Bì´ê³  ì¹˜ì—­ì´ Aì´ë©°, ëª¨ë“  $$y \\in B$$ì— ëŒ€í•´ $$f^{-1}(y) = x \\Leftrightarrow f(x) = y$$ ë¡œ ì •ì˜ë©ë‹ˆë‹¤. ğŸ”„ * **ê·¸ë˜í”„:** $$f^{-1}$$ì˜ ê·¸ë˜í”„ëŠ” $$f$$ì˜ ê·¸ë˜í”„ë¥¼...\n",
      "\n",
      "--- Chunk #5 ---\n",
      "URL       : https://ema.com/theory/01\n",
      "Headers   : {'Header 1': 'í•¨ìˆ˜ì™€ ì—­í•¨ìˆ˜', 'Header 2': 'ì—­ì‚¼ê°í•¨ìˆ˜', 'Header 3': 'ì—­ì‚¬ì¸ í•¨ìˆ˜'}\n",
      "Preview   : ## ì—­ì‚¼ê°í•¨ìˆ˜   ### ì—­ì‚¬ì¸ í•¨ìˆ˜   * **ì •ì˜:** ì—­ì‚¬ì¸ í•¨ìˆ˜ $$f(x) = \\sin^{-1}x$$ ëŠ” $$\\sin y = x$$ ì´ê³  $$-\\frac{\\pi}{2} \\le y \\le \\frac{\\pi}{2}$$ ë¥¼ ë§Œì¡±í•˜ëŠ” y ê°’ìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤. * **ì •ì˜ì—­:** $$-1 \\le x \\le 1$$ * **ì¹˜ì—­:** $$-\\frac{\\pi}{...\n",
      "\n",
      "--- Chunk #6 ---\n",
      "URL       : https://ema.com/theory/01\n",
      "Headers   : {'Header 1': 'í•¨ìˆ˜ì™€ ì—­í•¨ìˆ˜', 'Header 2': 'ì—­ì‚¼ê°í•¨ìˆ˜', 'Header 3': 'ì—­ì½”ì‚¬ì¸ í•¨ìˆ˜'}\n",
      "Preview   : ### ì—­ì½”ì‚¬ì¸ í•¨ìˆ˜   * **ì •ì˜:** ì—­ì½”ì‚¬ì¸ í•¨ìˆ˜ $$f(x) = \\cos^{-1}x$$ ëŠ” $$\\cos y = x$$ ì´ê³  $$0 \\le y \\le \\pi$$ ë¥¼ ë§Œì¡±í•˜ëŠ” y ê°’ìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤. * **ì •ì˜ì—­:** $$-1 \\le x \\le 1$$ * **ì¹˜ì—­:** $$0 \\le y \\le \\pi$$...\n",
      "\n",
      "--- Chunk #7 ---\n",
      "URL       : https://ema.com/theory/01\n",
      "Headers   : {'Header 1': 'í•¨ìˆ˜ì™€ ì—­í•¨ìˆ˜', 'Header 2': 'í•©ì„±í•¨ìˆ˜ì™€ ì •ì˜ì—­'}\n",
      "Preview   : ## í•©ì„±í•¨ìˆ˜ì™€ ì •ì˜ì—­   * **í•©ì„±í•¨ìˆ˜ì˜ ì •ì˜:** ë‘ í•¨ìˆ˜ fì™€ tì˜ í•©ì„±í•¨ìˆ˜ëŠ” $$(f \\circ t)(x) = f(t(x))$$ ë¡œ ì •ì˜ë©ë‹ˆë‹¤. ğŸ“Œ * **í•©ì„±í•¨ìˆ˜ì˜ ì •ì˜ì—­:** fì™€ tì˜ í•©ì„±í•¨ìˆ˜ì˜ ì •ì˜ì—­ì€ tì˜ ì •ì˜ì—­ê³¼ fì˜ ì •ì˜ì—­ì˜ êµì§‘í•© ì¤‘ì—ì„œ t(x)ê°€ fì˜ ì •ì˜ì—­ì— í¬í•¨ë˜ëŠ” xì˜ ì§‘í•©ì…ë‹ˆë‹¤.  ì¦‰,  $$ \\{ x | x \\in (A \\...\n",
      "\n",
      "--- Chunk #8 ---\n",
      "URL       : https://ema.com/theory/01\n",
      "Headers   : {'Header 1': 'í•¨ìˆ˜ì™€ ì—­í•¨ìˆ˜', 'Header 2': 'í•¨ìˆ˜ì˜ ê³±ê³¼ ì •ì˜ì—­'}\n",
      "Preview   : ## í•¨ìˆ˜ì˜ ê³±ê³¼ ì •ì˜ì—­   * í•¨ìˆ˜ fì™€ tì˜ ê³± ftì˜ ì •ì˜ì—­ì€ ë‘ í•¨ìˆ˜ì˜ ì •ì˜ì—­ì˜ êµì§‘í•©, ì¦‰ $$A \\cap B$$ ì…ë‹ˆë‹¤. * í•¨ìˆ˜ f/tì˜ ì •ì˜ì—­ì€ $$A \\cap B$$ ì—ì„œ $$t(x) = 0$$ ì¸ xë¥¼ ì œì™¸í•œ ì§‘í•©ì…ë‹ˆë‹¤....\n",
      "\n",
      "--- Chunk #9 ---\n",
      "URL       : https://ema.com/theory/01\n",
      "Headers   : {'Header 1': 'í•¨ìˆ˜ì™€ ê·¸ë˜í”„ ğŸ“ˆ', 'Header 2': 'ì—­í•¨ìˆ˜ì™€ ë³€í™˜ ğŸ”„'}\n",
      "Preview   : # í•¨ìˆ˜ì™€ ê·¸ë˜í”„ ğŸ“ˆ   ## ì—­í•¨ìˆ˜ì™€ ë³€í™˜ ğŸ”„   íƒ„ì  íŠ¸ í•¨ìˆ˜ì˜ ì—­í•¨ìˆ˜ì™€ ê·¸ë˜í”„ì˜ ì´ë™, ë°˜ì‚¬ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤....\n",
      "\n",
      "--- Chunk #10 ---\n",
      "URL       : https://ema.com/theory/01\n",
      "Headers   : {'Header 1': 'í•¨ìˆ˜ì™€ ê·¸ë˜í”„ ğŸ“ˆ', 'Header 2': 'ì—­í•¨ìˆ˜ì™€ ë³€í™˜ ğŸ”„', 'Header 3': 'ì—­ íƒ„ì  íŠ¸ í•¨ìˆ˜'}\n",
      "Preview   : ### ì—­ íƒ„ì  íŠ¸ í•¨ìˆ˜   ì—­ íƒ„ì  íŠ¸ í•¨ìˆ˜ $f(x) = \\tan^{-1}x$ ëŠ” $\\tan y = x$ ì´ê³  $-\\frac{\\pi}{2} < y < \\frac{\\pi}{2}$ ë¥¼ ë§Œì¡±í•˜ëŠ” í•¨ìˆ˜ë¡œ ì •ì˜ë©ë‹ˆë‹¤. ğŸ¤”   ì •ì˜ì—­ì€ ëª¨ë“  ì‹¤ìˆ˜($\\mathbb{R}$)ì´ê³ , ì¹˜ì—­ì€ $-\\frac{\\pi}{2} < y < \\frac{\\pi}{2}$ ì…ë‹ˆë‹¤....\n",
      "\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T06:19:36.825906Z",
     "start_time": "2025-05-10T06:07:24.160802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/gemini-embedding-exp-03-07\"\n",
    ")\n",
    "md_embedding = BatchedEmbeddings(\n",
    "    base=base_embeddings,\n",
    "    batch_size=16  # í•„ìš”ì— ë”°ë¼ ì¡°ì ˆí•˜ì„¸ìš”\n",
    ")\n",
    "\n",
    "# 6. FAISS VectorStore ìƒì„± (ë‚´ë¶€ì—ì„œ batch ë‹¨ìœ„ë¡œ ì„ë² ë”© ì²˜ë¦¬)\n",
    "md_vectorstore = FAISS.from_documents(md_docs_split, md_embedding)\n",
    "\n",
    "# 7. Retriever ìƒì„± ë° í™•ì¸\n",
    "md_retriever = md_vectorstore.as_retriever()\n",
    "print(f\"ì´ ì²­í¬ ìˆ˜: {len(md_docs)}\")\n",
    "print(f\"ì²« ì²­í¬ ë¯¸ë¦¬ë³´ê¸°:\\n{md_docs[0].page_content[:300]}\")"
   ],
   "id": "74ebde9d720d07c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep  0\n",
      "sleep  16\n",
      "sleep  32\n",
      "sleep  48\n",
      "sleep  64\n",
      "sleep  80\n",
      "sleep  96\n",
      "sleep  112\n",
      "sleep  128\n",
      "sleep  144\n",
      "sleep  160\n",
      "sleep  176\n",
      "sleep  192\n",
      "sleep  208\n",
      "sleep  224\n",
      "sleep  240\n",
      "sleep  256\n",
      "sleep  272\n",
      "sleep  288\n",
      "sleep  304\n",
      "sleep  320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì²­í¬ ìˆ˜: 15\n",
      "ì²« ì²­í¬ ë¯¸ë¦¬ë³´ê¸°:\n",
      "# Chapter 01 Functions and Models\n",
      "\n",
      "# í•¨ìˆ˜ì™€ ì—­í•¨ìˆ˜\n",
      "\n",
      "## í•¨ìˆ˜ì˜ ë³€í™˜\n",
      "\n",
      "ë‹¤ìŒì€ í•¨ìˆ˜ ê·¸ë˜í”„ì˜ ë³€í™˜ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤.  ğŸ˜€\n",
      "\n",
      "* yì¶• ëŒ€ì¹­: $$y = f(-x)$$\n",
      "* xì¶• ëŒ€ì¹­: $$y = -f(x)$$\n",
      "* yì¶• ë°©í–¥ìœ¼ë¡œ 2ë°° í™•ëŒ€: $$y = 2f(x)$$\n",
      "* yì¶• ë°©í–¥ìœ¼ë¡œ 1/2ë°° ì¶•ì†Œ: $$y = \\frac{1}{2}f(x)$$\n",
      "* xì¶• ë°©í–¥ìœ¼ë¡œ 2ë°° í™•ëŒ€: $$y = f(\\frac{1}{2}x)$$\n",
      "* xì¶• ë°©í–¥ìœ¼ë¡œ 1/2ë°° ì¶•ì†Œ: $$y = f(2x)$$\n",
      "\n",
      "\n",
      "## ì¼ëŒ€ì¼ í•¨ìˆ˜ì™€ ì—­í•¨ìˆ˜\n",
      "\n",
      "#\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T06:19:48.936262Z",
     "start_time": "2025-05-10T06:19:48.911192Z"
    }
   },
   "cell_type": "code",
   "source": "md_vectorstore.save_local(\"md_vectorstore\")",
   "id": "760cba79dc1bd9de",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T06:36:00.806444Z",
     "start_time": "2025-05-10T06:35:59.537420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 6. FAISS VectorStore ìƒì„± (ë‚´ë¶€ì—ì„œ batch ë‹¨ìœ„ë¡œ ì„ë² ë”© ì²˜ë¦¬)\n",
    "md_vectorstore = FAISS.load_local(\"md_vectorstore\", base_embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# 7. Retriever ìƒì„± ë° í™•ì¸\n",
    "md_retriever = md_vectorstore.as_retriever()\n",
    "\n",
    "result = md_retriever.invoke(\"ì •ì ë¶„ì´ ë­ì•¼?\")\n",
    "print(result[0].metadata[\"url\"])"
   ],
   "id": "9c29c5edcded3e2a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ema.com/theory/04\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T07:38:17.960837Z",
     "start_time": "2025-05-10T07:38:17.947805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.tools import Tool\n",
    "def calculus_search_fn(query: str) -> list[dict]:\n",
    "    docs = calculus_retriever.get_relevant_documents(query)\n",
    "    return [\n",
    "        {\n",
    "            \"text\": doc.page_content,\n",
    "            \"chapter\": doc.metadata.get(\"Header 1\"),\n",
    "            \"section\": doc.metadata.get(\"Header 2\")\n",
    "        }\n",
    "        for doc in docs\n",
    "    ]\n",
    "\n",
    "calculus_tool = Tool.from_function(\n",
    "    calculus_search_fn,\n",
    "    name=\"calculus_search\",\n",
    "    description = (\n",
    "        \"Use this tool for semantic retrieval over the Calculus textbook, \"\n",
    "        \"optimized for scholarly and academic-level inquiries. Given a userâ€™s \"\n",
    "        \"natural-language question about any calculus concept (e.g., definitions, \"\n",
    "        \"theorems, proofs, examples, formulas, applications), return the most \"\n",
    "        \"relevant textbook sections and excerpts along with metadata (chapter and \"\n",
    "        \"section headings) so that the agent can provide accurate, \"\n",
    "        \"context-aware, and authoritative answers.\"\n",
    "    )\n",
    ")\n",
    "# ì´ ë„êµ¬ëŠ” ë¯¸ì ë¶„ êµì¬ ì „ì²´ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•™ìˆ ì  ìˆ˜ì¤€ì˜ ì‹¬ë„ ìˆëŠ” ì§ˆë¬¸ì— ìµœì í™”ëœ ì‹œë§¨í‹± ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "# ì‚¬ìš©ìê°€ ë¯¸ì ë¶„ ê°œë…(ì˜ˆ: ì •ì˜, ì •ë¦¬, ì¦ëª…, ì˜ˆì œ, ê³µì‹, ì‘ìš© ë“±)ì— ëŒ€í•´ ìì—°ì–´ë¡œ ë¬»ëŠ” ê²½ìš°,\n",
    "# ì±•í„°Â·ë‹¨ì› ì œëª©ê³¼ URL ë“±ì˜ ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ êµì¬ ë°œì·Œë¥¼ ë°˜í™˜í•˜ì—¬\n",
    "# ì—ì´ì „íŠ¸ê°€ ì •í™•í•˜ê³  ë§¥ë½ì— ë§ìœ¼ë©° ê¶Œìœ„ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\n",
    "def md_search_fn(query: str) -> list[dict]:\n",
    "    docs = md_retriever.get_relevant_documents(query)\n",
    "    return [\n",
    "        {\n",
    "            \"text\": doc.page_content,\n",
    "            \"chapter\": doc.metadata.get(\"Header 1\"),\n",
    "            \"section\": doc.metadata.get(\"Header 2\"),\n",
    "            \"url\": doc.metadata[\"url\"],\n",
    "        }\n",
    "        for doc in docs\n",
    "    ]\n",
    "\n",
    "md_tool = Tool.from_function(\n",
    "    md_search_fn,\n",
    "    name=\"md_search\",\n",
    "    description=(\n",
    "        \"Use this tool to semantically search the user-friendly, markdown-formatted study guide for calculus. \"\n",
    "        \"Given a natural-language question about any calculus concept, it returns the most relevant markdown summary \"\n",
    "        \"sections along with their static page URLs, enabling the agent to suggest â€œplease check this page for more details.â€\"\n",
    "    )\n",
    ")\n",
    "# ì´ ë„êµ¬ëŠ” ì‚¬ìš©ì ì¹œí™”ì ì¸ Markdown í˜•ì‹ì˜ ë¯¸ì ë¶„ í•™ìŠµ ê°€ì´ë“œë¥¼ ì‹œë§¨í‹± ê²€ìƒ‰í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "# í•™ìˆ  ìˆ˜ì¤€ì˜ ì§ˆë¬¸ê³¼ ë³´ë‹¤ ì‹¬ë„ ìˆëŠ” ê°œë… ì´í•´ë¥¼ ì§€ì›í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ê°„ê²°í•œ ì„¤ëª…ê³¼\n",
    "# í•´ë‹¹ ì •ì  í˜ì´ì§€ URLì„ ë°˜í™˜í•©ë‹ˆë‹¤. ì—ì´ì „íŠ¸ëŠ” â€œë³´ë‹¤ í•™ìˆ ì ì¸ ê°œìš”ë‚˜ ìì„¸í•œ ì˜ˆì‹œëŠ” ì´ í˜ì´ì§€ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”â€\n",
    "# ë¼ê³  ì œì•ˆí•  ë•Œ ì´ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ë©´ ë©ë‹ˆë‹¤."
   ],
   "id": "64e979b8ebb8f1f",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T06:36:08.042528Z",
     "start_time": "2025-05-10T06:36:08.035055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "calculus_retriever_tool = create_retriever_tool(\n",
    "    calculus_retriever,\n",
    "    name = \"calculus_search\",\n",
    "    description = (\n",
    "        \"Use this tool for semantic retrieval over the Calculus textbook, \"\n",
    "        \"optimized for scholarly and academic-level inquiries. Given a userâ€™s \"\n",
    "        \"natural-language question about any calculus concept (e.g., definitions, \"\n",
    "        \"theorems, proofs, examples, formulas, applications), return the most \"\n",
    "        \"relevant textbook sections and excerpts along with metadata (chapter and \"\n",
    "        \"section headings) so that the agent can provide accurate, \"\n",
    "        \"context-aware, and authoritative answers.\"\n",
    "    )\n",
    ")\n",
    "# ì´ ë„êµ¬ëŠ” ë¯¸ì ë¶„ êµì¬ ì „ì²´ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•™ìˆ ì  ìˆ˜ì¤€ì˜ ì‹¬ë„ ìˆëŠ” ì§ˆë¬¸ì— ìµœì í™”ëœ ì‹œë§¨í‹± ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "# ì‚¬ìš©ìê°€ ë¯¸ì ë¶„ ê°œë…(ì˜ˆ: ì •ì˜, ì •ë¦¬, ì¦ëª…, ì˜ˆì œ, ê³µì‹, ì‘ìš© ë“±)ì— ëŒ€í•´ ìì—°ì–´ë¡œ ë¬»ëŠ” ê²½ìš°,\n",
    "# ì±•í„°Â·ë‹¨ì› ì œëª©ê³¼ URL ë“±ì˜ ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ êµì¬ ë°œì·Œë¥¼ ë°˜í™˜í•˜ì—¬\n",
    "# ì—ì´ì „íŠ¸ê°€ ì •í™•í•˜ê³  ë§¥ë½ì— ë§ìœ¼ë©° ê¶Œìœ„ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\n",
    "md_retriever_tool = create_retriever_tool(\n",
    "    md_retriever,\n",
    "    name=\"md_search\",\n",
    "    description=(\n",
    "        \"Use this tool to semantically search the user-friendly, markdown-formatted study guide for calculus. \"\n",
    "        \"Given a natural-language question about any calculus concept, it returns the most relevant markdown summary \"\n",
    "        \"sections along with their static page URLs, enabling the agent to suggest â€œplease check this page for more details.â€\"\n",
    "    )\n",
    ")\n",
    "# ì´ ë„êµ¬ëŠ” ì‚¬ìš©ì ì¹œí™”ì ì¸ Markdown í˜•ì‹ì˜ ë¯¸ì ë¶„ í•™ìŠµ ê°€ì´ë“œë¥¼ ì‹œë§¨í‹± ê²€ìƒ‰í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "# í•™ìˆ  ìˆ˜ì¤€ì˜ ì§ˆë¬¸ê³¼ ë³´ë‹¤ ì‹¬ë„ ìˆëŠ” ê°œë… ì´í•´ë¥¼ ì§€ì›í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ê°„ê²°í•œ ì„¤ëª…ê³¼\n",
    "# í•´ë‹¹ ì •ì  í˜ì´ì§€ URLì„ ë°˜í™˜í•©ë‹ˆë‹¤. ì—ì´ì „íŠ¸ëŠ” â€œë³´ë‹¤ í•™ìˆ ì ì¸ ê°œìš”ë‚˜ ìì„¸í•œ ì˜ˆì‹œëŠ” ì´ í˜ì´ì§€ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”â€\n",
    "# ë¼ê³  ì œì•ˆí•  ë•Œ ì´ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ë©´ ë©ë‹ˆë‹¤."
   ],
   "id": "3c24a0001789123e",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T07:38:49.997950Z",
     "start_time": "2025-05-10T07:38:49.984342Z"
    }
   },
   "cell_type": "code",
   "source": "tools = [calculus_tool, md_tool]",
   "id": "743b55ce4ad45326",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T07:39:14.315814Z",
     "start_time": "2025-05-10T07:39:14.301605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# LLM ì •ì˜\n",
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-2.0-flash\", temperature=0.2)\n",
    "\n",
    "# Prompt ì •ì˜\n",
    "theory_explanation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are the â€˜Theory Explanation Agentâ€™, specialized in answering and explaining calculus concepts. \"\n",
    "            \"When the user asks a theoretical question about calculus, you should:\\n\"\n",
    "            \"1. Use the `calculus_search` tool to semantically retrieve authoritative passages from the Calculus textbook.\\n\"\n",
    "            \"2. Use the `md_search` tool to fetch relevant markdown-formatted study guide sections and their static page URLs.\\n\"\n",
    "            \"3. Please answer in a way thatâ€™s easy for Koreans to understand.\\n\"\n",
    "            \"Always cite the retrieved context in your explanation. If neither tool yields an answer, fall back to your internal knowledge. \"\n",
    "            \"Structure your response as a clear, scholarly explanation, and suggest the static page URL when appropriate.\"\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# system:\n",
    "# â€œë‹¹ì‹ ì€ â€˜ì´ë¡ ì„¤ëª… ì—ì´ì „íŠ¸â€™ë¡œ, ë¯¸ì ë¶„ ì´ë¡  ì§ˆë¬¸ì— ë‹µí•˜ê³  ê°œë…ì„ ì„¤ëª…í•˜ëŠ” ë° íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "# ì‚¬ìš©ìê°€ ë¯¸ì ë¶„ ì´ë¡ ì— ëŒ€í•´ ë¬»ëŠ” ê²½ìš° ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
    "# \n",
    "# calculus_search ë„êµ¬ë¥¼ ì‚¬ìš©í•´ êµì¬ì—ì„œ ê¶Œìœ„ ìˆëŠ” ë‚´ìš©ì„ ì‹œë§¨í‹± ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "# \n",
    "# md_search ë„êµ¬ë¥¼ ì‚¬ìš©í•´ Markdown í˜•ì‹ í•™ìŠµ ê°€ì´ë“œì˜ ê´€ë ¨ ì„¹ì…˜ê³¼ ì •ì  í˜ì´ì§€ URLì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "# ê²€ìƒ‰í•œ ì»¨í…ìŠ¤íŠ¸ëŠ” ì„¤ëª…ì— ë°˜ë“œì‹œ ì¸ìš©í•˜ì„¸ìš”. ë„êµ¬ë¡œ ë‹µì„ ì°¾ì§€ ëª»í•˜ë©´ ë‚´ë¶€ ì§€ì‹ì„ í™œìš©í•©ë‹ˆë‹¤.\n",
    "# ë‹µë³€ì€ í•™ìˆ ì ìœ¼ë¡œ ëª…í™•í•˜ê²Œ êµ¬ì„±í•˜ê³ , í•„ìš” ì‹œ ì •ì  í˜ì´ì§€ URLì„ ì œì•ˆí•˜ì„¸ìš”.â€"
   ],
   "id": "85ae5f9f042fb9f2",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T07:39:17.937805Z",
     "start_time": "2025-05-10T07:39:17.903150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "# tool calling agent ìƒì„±\n",
    "agent = create_tool_calling_agent(llm, tools, theory_explanation_prompt)\n"
   ],
   "id": "f627135931a14b4f",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T07:39:47.437031Z",
     "start_time": "2025-05-10T07:39:47.419890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# AgentExecutor ìƒì„±\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)"
   ],
   "id": "6596a56c062a5db0",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T08:20:01.102584Z",
     "start_time": "2025-05-10T08:20:01.096936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_teddynote.messages import AgentStreamParser\n",
    "\n",
    "# ê° ë‹¨ê³„ë³„ ì¶œë ¥ì„ ìœ„í•œ íŒŒì„œ ìƒì„±\n",
    "agent_stream_parser = AgentStreamParser()"
   ],
   "id": "7b9f7bd45f5051df",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T08:27:50.527095Z",
     "start_time": "2025-05-10T08:27:45.885753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ì§ˆì˜ì— ëŒ€í•œ ë‹µë³€ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì¶œë ¥ ìš”ì²­\n",
    "result = agent_executor.invoke(\n",
    "    {\"input\": \"âˆ«xe^xdx ë¥¼ ë¶€ë¶„ì ë¶„ë²•(Integration by Parts)ì„ í•˜ê¸°ê°€ ì–´ë µë„¤. ê³µë¶€í•  ìˆ˜ ìˆëŠ” í˜ì´ì§€ ìˆì–´?\"}\n",
    ")\n",
    "\n",
    "for i in result:\n",
    "    print(result[i])\n"
   ],
   "id": "9278616e913f45b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âˆ«xe^xdx ë¥¼ ë¶€ë¶„ì ë¶„ë²•(Integration by Parts)ì„ í•˜ê¸°ê°€ ì–´ë µë„¤. ê³µë¶€í•  ìˆ˜ ìˆëŠ” í˜ì´ì§€ ìˆì–´?\n",
      " ë¶€ë¶„ì ë¶„ë²•ì€ ê³±ì˜ í˜•íƒœë¡œ ì´ë£¨ì–´ì§„ í•¨ìˆ˜ì˜ ì ë¶„ì„ ê³„ì‚°í•˜ëŠ” ë° ìœ ìš©í•œ ê¸°ë²•ì…ë‹ˆë‹¤. (https://ema.com/theory/07)\n",
      "\n",
      "ë¶€ë¶„ì ë¶„ ê³µì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "$\\\\int u dv = uv - \\\\int v du$\n",
      "\n",
      "$\\\\int xe^x dx$ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´, uì™€ dvë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ uëŠ” ë¯¸ë¶„í–ˆì„ ë•Œ ë” ê°„ë‹¨í•´ì§€ëŠ” í•¨ìˆ˜ë¡œ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì´ ê²½ìš°, xë¥¼ uë¡œ, $e^x dx$ë¥¼ dvë¡œ ì„ íƒí•©ë‹ˆë‹¤.\n",
      "\n",
      "u = x, dv = $e^x dx$\n",
      "du = dx, v = $e^x$\n",
      "\n",
      "ë¶€ë¶„ì ë¶„ ê³µì‹ì— ëŒ€ì…í•˜ë©´:\n",
      "$\\\\int xe^x dx = xe^x - \\\\int e^x dx = xe^x - e^x + C$\n",
      "\n",
      "ë”°ë¼ì„œ, $\\\\int xe^x dx = xe^x - e^x + C$ì…ë‹ˆë‹¤.\n",
      "\n",
      "ìì„¸í•œ ë‚´ìš©ì€ ë‹¤ìŒ í˜ì´ì§€ë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤: https://ema.com/theory/07\n",
      "\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8e39cb1103137462"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
